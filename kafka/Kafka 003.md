# Kafka 003





# 파티셔너 (Partitioner)

- 데이터를 토픽의 어떤 파티션에 넣을지 결정하는 역할을 한다.
- 따로 설정하지 않는다면 기본으로 `UniformStickyPartitioner` 로 설정된다.
  - 메시지키가 있을 경우
    - 파티션 번호 = hash(메시지 키) 로 계산되어 각 파티션으로 분배된다.
    - 동일한 메시지키는 동일한 파티션으로 들어간다.
  - 메시지키가 없을 경우
    - 라운드로빈
    - 배치단위로 데이터를 보내고, 적절히 파티션에 배분된다.
- 커스텀 파티셔너 (Partitioner Interface 구현)
  - 예) VIP 고객을 위해 데이터 처리를 조금 더 빨리 구현할 때 10개의 파티션 중 8개로 배분되도록 한다.
  - AMQP 기반 메시징 시스템에서 우선순위 큐를 만드는 것과 비슷하다고 생각하면 된다.

<br />

# Kafka Streams

- Java, Golang, Python
- 카프카에서 공식적으로 제공하는 자바 라이브러리 
  - JVM 기반언어 Java, Kotlin, Scala 중 하나 선택해서 사용



## 장점

### 1) 카프카 클러스터와 완벽 연동된다. (버전 호환)

- 카프카를 사용하고 있고, 데이터를 안전하고 빠르게 처리하고 싶다 스트림즈를 1순위로 고려한다.

### 2) 스케쥴링 도구가 필요없다.

- 카프카아 연동하는 스트림 프로세싱 툴로 가장 많이, 널리 사용하는 것은 `스파크 스트림`
  - 스파크를 운여하기 위해서는 yarn, mesos 와 같이 클러스터 관리자 또는 리소스 매니저가 필요하다.
  - 대규모 장비도 구축해야 한다.
- 하지만 카프카 스트림즈를 사용하면 스케쥴링 도구는 필요가 없다.

### 3) 스트림즈 DSL 과 프로세서 API 를 제공한다.

- Streams DSL 은 이벤트기반 데이터 처리 map, join, window 등의 편의 메소드를 제공한다. (많이 지원)
- 없는 기능은 프로세서 API 를 사용한다.
- KStream, KTable, GlobalKTable 은 독특한 스트림 처리 개념
  - 대규모 key-value 저장소로도 활용 가능

### 4) 로컬 상태저장소를 사용한다.

실시간으로 들어오는 데이터를 처리하는 방식

- 비상태기반 처리 (stateless)
  - 필터링 또는 데이터를 변환하는 처리
  - 데이터가 들어오는 족족 바로 처리하고 프로듀스한다. 유실이나 중복이 발생할 염려가 적고, 쉽게 개발 가능
- 상태기반 처리
  - 윈도우, 조인, 취합(aggregation) 등은 이전 상태를 메모리에 저장하고, 다음 데이터를 참조해서 처리해야 한다.
  - Streams 는 로컬에 rocksdb 를 사용해서 상태를 저장하고, 상태 변환 정보는 카프카의 변경로그 (changelog) 토픽에 저장한다.
    - 프로세서에 장애가 발생하더라도 상태가 안전하게 저장되므로, 자연스럽게 장애 복구 가능하다.

```java
KStream<String, String> paymentStream = builder.stream("payment");
KStream<String, String> filteredStream = paymentStream
	.filter((key, value) -> key.equals("unknown"));
filteredStream.to("unknown-payment");
```

<br />

# Kafka Connect - 데이터 파이프라인을 효율적으로 개발, 배포, 운영

- 커넥트 - 커넥터를 동작하도록 실행해주는 프로세스
- 커넥터 - 실제 데이터를 처리하는 코드가 담긴 jar 패키

## 커넥터

- 싱크 커넥터 (Sink Connector)
  - 특정 토픽 데이터를 다른 DB 로 저장하는 역할
    - 예) OracleSinkConnector
  - 컨슈머와 같은 역할
- 소스 커넥터 (Source Connector)
  - DB 로 부터 데이터를 가져와 토픽에 넣는 역할
  - 프로듀서 역할



## 커넥트

- 단일 실행모드 커넥트
  - 간단한 구성, 개발용
- 분산 모드 커넥트
  - 실제 운영용
  - 여러개의 프로세스를 한 클러스터로 묶어서 운영
  - 일부 커넥트에 장애가 발생해도 나머지 실행되고있는 커넥터에 연결해서 자연스럽게 Failover 가능



## 커넥트와 커넥터

커넥터 경로 설정

```shell
plugin.path=/var/connectors
```



- 실행중인 커넥트에서 커넥터를 실행하려면, REST API 사용
- REST API 를 통해 커넥터를 통한 파이프라인들이 분산해서 생긴다.
- 예를들어 OracleSinkConnector 가 있다면, 토픽의 데이터를 JSON 으로 변경하고, REST API 를 통해 커넥트에 POST 명령을 내린다.
  - 그 후 커넥트에 파이프라인이 생성된다.
- 커넥터는 검색해서 찾아보면 이미 만들어져있는 오픈소스가 많다.

<br />

# 카파 아키텍처, 람다 아키텍처

- end-to-end 로 각 서비스 애플리케이션으로부터 데이터를 배치로 모았다.
  - 유연하지 못하다.
  - 실시간으로 생성되는 데이터들에 대한 인사이트를 서비스 애플리케이션에 반영할 수 없다.
  - 원천 데이터로부터 파생된 데이터 히스토리를 파악하기 어려웠다.
  - 계속되는 데이터의 가공으로 인해 데이터가 파편화되면서 데이터 거버넌스를 지키기 어려워 졌다.
    - 거버넌스란 빅데이터에 대한 체계적 관리와 통제를 말한다.
    - 프라이버시, 품질, 데이터 생명주기 같은 것을 말한다.
- 이런 단점을 해결하려고 만들어진 것이 람다 아키텍처



## 람다 아키텍처

![](https://i.ibb.co/YkpqHbp/2022-01-26-9-02-08.png)

3가지 레이어

- 배치 레이어
  - 특정 시간마다 일괄 처리
- 서빙 레이어
  - 가공된 데이터를 사용자, 서비스 애플리케이션에게 제공하기 위해 데이터가 저장된 공간 (Hadoop)
- 스피드 레이어
  - 서비스에서 생성되는 데이터를 실시간 분석
  - 낮은 지연시간
  - 카프카와 같은 이벤트 스트피링 플랫폼

단점

- 레이어가 2개로 나뉘기 때문에 데이터를 분석 처리 하는 로직이 2벌로 각각의 레이어에 따로 존재해야 한다.
- 배치 데이터와 실시간 데이터를 융합하여 처리할 때는 유연하지 못한 파이프라인을 생성해야 했다.
- 이를 해결하기 위해 카파 아키텍처 제안

<br />

## 카파 아키텍처

제이 크렙스 (카프카 최초로 고안한 개발자, 전 링크드인 팀장, 현 컨플루언트 CEO)

![](https://i.ibb.co/sw7ryxg/2022-01-26-9-07-49.png)

- 람다 아키텍처의 단점이 로직의 파편화, 디버깅, 배포, 운영 분리에 대한 이슈를 제거하기 위해 배치 레이어를 제거
- 스피드 레이어에서 모두 처리하여 엔지니어들은 개발과 운영에 효율적으로 임할 수 있었다.

<br />

## 스트리밍 데이터 레이크 (ing)

2020

- 서빙 레어이도 제거
- 이를 위해 스트리밍 데이터를 배치 데이터로 자유롭게 접근 가능해야 한다.
- 스트리밍 데이터는 타임 스탬프 기준으로 쿼리를 돌려 배치형태로 데이터를 일부 뽑아 낼 수는 있지만, 오리지널 아파치 카프카로는 한계가 있다.
- 자주 접근하지 않는 데이터를 비싼 자원에 유지할 필요가 없다.
  - 오브젝트 스토리지와 같이 저렴하면서도 안정한 데이터 저장소에 옮겨 저장한다.
  - 자주 사용하는 데이터만 브로커에서 사용하는 구분 작업이 필요하다.



