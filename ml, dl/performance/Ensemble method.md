# Ensemble method



## 1. Why use ensemble?

1) 나쁜 운을 피할 수 있습니다.

2) 성능 향상을 할 수 있습니다.

3) 데이터 부족/과다를 해결할 수 있습니다.

​	데이터가 부족할 땐 같은 샘플을 여러 번 사용하는 배깅이나 부스팅 같은 재샘플링 기법이 있습니다. 반면, 데이터 양이 많을 때, 앙상블을 사용하면 효과적입니다.

4) 데이터 질을 극복할 수 있습니다.

5) 다중 센서 시스템에 효과적 입니다.

​	데이터는 표현 뿐 아니라, 내용에도 차이가 있어 너무 일찍 융합하면 여러 센서로 검사한 취지가 사라질 수 있습니다. 앙상블을 통해 데이터마다 원하는 시점에서 별도의 분류기를 만들어 융합할 수 있습니다.

6) 점진 학습(incremental learning)이 가능합니다.

​	새로 발생한 데이터와 추가된 부류를 처리할 수 있는 분류기를 만들고, 기존 앙상블에 추가하는 방식의 점진 학습은 효과적입니다.



### 요소 분류기(Component Classifier)의 다양성

앙상블 기법은 분류, 회구문제 모두 적용할 수 있는데, 주로 분류에 적용합니다.

요소(개인) 분류기는 다양하면 좋습니다. 그래야 여러 의견을 담아 합쳤을 때 성능 향상을 꾀할 수 있기 때문입니다.

요소분류기의 다양성을 측정하는 척도로 다음이 있습니다.
$$
E = \frac{1}{n(T - \lceil{\frac{T}{2}}\rceil)}\sum_{i=1}^n min(l_i, T-l_i)
$$
T는 분류기의 개수, n은 샘플의 개수, $l_i$는 i번째 샘플이 맞춘 분류기의 갯수 입니다. 척도는 [0,1] 값을 가지는데 모든 분류기가 같을 때 0이고, 가장 다양할 때 1이 됩니다.



분류기 3개의 예를 들어봅시다.

정답레이블은 1111100000인 상황입니다. 이에 대해 다음 분류기는 옆 ()와 같은 정확도를 냅니다.

$c_1$ : 1011101100(0.7)

$c_{2}$ : 1011101100(0.7)

$c_3$ : 1011101100(0.7)

3개의 분류기를 합쳐서 투표하는 상황을 봅시다.

1011101100(0.7) 다음과 같이 같은 결과를 냅니다.

척도를 계산해봅시다.
$$
E = \frac{1}{10 * 1}(0 + 0 + 0 + 0 +0+0+0+0+0+0) = 0
$$
으로 개별 분류기의 다양성은 0입니다. 이런 분류기는 앙상블에 추가연산비용만 들고 성능은 전혀 늘지 않습니다.



반면, 

$c_4$ : 1011101001(0.7)

$c_{5}$ : 1110100110(0.7)

$c_6$ : 0101110000(0.7)

이 경우를 보면 투표했을 때

1111100000(1.0) 로 100% 의 성능이 나오며, 위에 보다 30%의 정확도 개선을 하였습니다.

척도를 계산해보면,
$$
E = \frac{1}{10 * 1}(1 + 1+ 1+1+0+1+1+1+1+1)=0.9
$$
로 분류기들의 다양성은 1에 가까운 값으로 매우 높아진 것을 확인할 수 있습니다.

이처럼 **높은 다양성**을 가진 요소 분류기를 사용하여 **투표 방식(voting)**으로 분류를 하면, **성능향상이 가능한 경우가 많습니다.**



	## 2. 재샘플링 기법(Resampling Method)

### Bagging

배깅은 **B**ootstrap **agg**regat**ing** 의 약자입니다. (Breiman, 1996)

부트스트랩에 앙상블을 적용한 알고리즘입니다. 비교적 단순하지만, 뛰어난 성능 향상을 보여줍니다. 



T개의 학습된 분류기로 앙상블합니다. 매 반복마다 중복으로 추출하는 것을 허용하여 각각의 분류기를 학습합니다. 배깅으로 만든 분류기는 **투표**와 같은 기법으로 결합합니다.



**알고리즘 Bagging**

![](https://i.ibb.co/MhCmkmF/image.png)



### Boosting

부스팅은 배깅보다 정교한 재샘플링 연산을 합니다. 

t번째 분류기와 t+1번째 분류기가 연관성을 가지도록 학습합니다.

핵심은 훈련 샘플 중 $c_t$가 맞춘 샘플은 인식 가능하므로 가중치를 낮추고, 틀린 샘플은 가중치를 높이는 것입니다.



**사파이어 알고리즘**

1) $\mathbb{X}$에서 임의로 부분집합 $\mathbb{X}'$를 뽑습니다.

2) $\mathbb{X}'$로 약한 분류기(weak classifier) $c_1$을 학습합니다. 이 때 맞히는 샘플과 틀리는 샘플이 반반 되도록 $\mathbb{X}$에서 임의로 샘플을 뽑아 $\mathbb{X}'$를 구성합니다.

3) $\mathbb{X}'$로약한 분류기 $c_2$을 학습합니다. 이 때는 $c_1$과 $c_2$가 다르게 분류하는 샘플을 $\mathbb{X}$에서 골라 $\mathbb{X}'$에 구성합니다.

4) $\mathbb{X}'$로 약한 분류기 $c_3$을 학습합니다.

5) 테스트 단계에서 $c_1, c_2$로 분류한 후 둘의 분류결과가 일치하면 답으로 취하고, 일치하지 않으면 $c_3$로 분류한 결과를 취합니다.



**AdaBoost**

이후 개선된 알고리즘 AdaBoost(Freund, 1997)를 소개합니다.

신뢰도(confidence)까지 출력하는 장점이 있습니다.

![](https://i.ibb.co/60zHm1r/image.png)

line 5 : 처음에 같은 가중치를 가지고 출발합니다.

line 14~16 : 새로운 분류기가 만들어질 때마다 가중치를 갱신합니다. 틀린샘플은 $exp(\alpha_t)$를 곱하여 가중치를 높이고, 맞힌 샘플은 $exp(-\alpha_t)$를 곱하여 가중치를 낮춥니다.

line 9~8 : 새로 제작한 분류기의 오류율을 가중치를 고려하여 계산합니다.

line 12 : $c_t$ 분류기의 오류율이 0.5보다 작을때(성능이 좋을때)만 채택하고, 그렇지 않으면 버립니다.

line 7 : $w_{t1} $~ $ w_{tn}$ 를 분류기 $c_t$를 학습하는데, 그 방법 중 2가지를 소개합니다.

​	첫 번째는 재샘플링을 이용한 방법으로, 샘플링할 때 가중치를 고려하므로 $\mathbb{X}'$는 가중치가 높은 샘플을 더 많이 가지게 되고 결국은 $c_t$는 이전 분류기가 틀린 샘플을 더 중요하게 취급하게 됩니다.

​	두 번째는 목적함수에 가중치를 반영하는 것입니다.
$$
J = \sum_{i=1}^n w_{ti} \Vert c_t(x_i) - y_i \Vert^2_2
$$
오류에 가중치를 곱하므로, 가중치가 큰 샘플을 틀리면 더 큰 벌칙을 주는 셈이 됩니다.





## 3. 결정트리(Decision Tree)와 랜덤 포리스트(Random Forest)

### 1) Decision Tree

**노드에서의 질문**

결정트리는 자식이 최대 2개인 이진트리를 사용합니다.

결정트리 알고리즘은 자동으로 질문을 만들어야 하는데,

​	1) 가능한 모든 후보에서 질문을 생성하는 문제

​	2) 후보 질문 중 가장 유리한 최적질문을 찾아내는 문제

​	를 생각해야 합니다.



후보질문 생성은 정수일 때는 각 정수마다 나누고, 실수 일 때는 구간별로 나눕니다.

예) $x_1 \in \{2, 3, 5, 7\}$ 일 때 $x_1$에 따른 후보 질문: $x_1 = 2?, x_1=3?, x_1=5?, x_1=7?$

예) $x_2 \in \{45.6, 47.8, 50.6, 65.3\}$ 일 때 $x_2$에 따른 후보 질문: $x_2<46.7?, x_2<49.2?, x_2<57.95?$



후보질문을 평가하여 최적의 질문을 결정해봅시다.

훈련집합의 불순도(impurity)를 측정해봅시다. 불순도는 부류 정보를 보고 결정하므로 $\mathbb{X}_T$대신 $\mathbb{Y}_T$를 사용합니다. 모든 샘플의 부류가 같으면 불순도 0이고, 다른 부류가 많이 섞여 있을 수록 불순도가 높습니다. 

종류로는 엔트포리 불순도, 지니 불순도, 오분류 불순도가 있습니다.


$$
entropy(\mathbb{Y}_T) = -\sum_{k=1}^c P(k|\mathbb{Y}_T) log_2\mathbb{Y}_T
$$

$$
gini(\mathbb{Y}_T) = 1 - \sum_{k=1}^c P(k|\mathbb{Y}_T)^2 = \sum_{j \ne k} P(j|\mathbb{Y}_T) P(k|\mathbb{Y}_T)
$$

$$
misclassification(\mathbb{Y}_T) = 1 - \underset{k}{max} P(k|\mathbb{Y}_T)
$$





$P(k|\mathbb{Y}_T) = \frac{부류 k의 샘플 수}{전체 샘플 수}$ 는 $\mathbb{Y}_T$에서 부류 k가 발생활 확률입니다.



불순도를 이용해서 후보 질문 q의 품질을 평가해봅시다.

불순도를 많이 낮출수록 좋은 질문입니다.

다음은 불순도를 낮추는 정도를 측정하는 불순도 감소량입니다. 단순히 부모 노드 불순도에서 자식 노드 불순도 합을 뺍니다. im은 불순도 함수로 entropy, Gini, misclassification 중 적당한 것을 사용하면 됩니다.


$$
delta\_im(q) = im(\mathbb{Y}_T) - (\frac{|\mathbb{Y}_{T_{left}}|}{|\mathbb{Y}_T|}im(\mathbb{Y}_{T_{left}}) + \frac{|\mathbb{Y}_{T_{right}}|}{|\mathbb{Y}_T|}im(\mathbb{Y}_{T_{right}}))
$$


또 다른 방법으로 투잉 기준(twoing criterion)이라는 방법도 있습니다.
$$
twoing(q) = \frac{|\mathbb{Y}_{T_{left}}|}{|\mathbb{Y}_T|}\frac{|\mathbb{Y}_{T_{left}}|}{|\mathbb{Y}_T|}(\sum_{k=1}^c |P(k|\mathbb{Y}_{T_{left}}) - P(k|\mathbb{Y}_{T_{right}})|)^2
$$


**학습 알고리즘**

![](https://i.ibb.co/xj8ywYB/image.png)

학습시 멈춤 조건을 완화하여 overfiting을 피할 수 있습니다. 불순도가 0이 아니더라도 충분히 낮으면 멈추는 것입니다.

> 조건 1: 불순도가 0이다.
>
> 조건 2: $\mathbb{X}_T$의 샘플 개수가 임곗값 이하이다.
>
> 조건 3: $\hat{q}$의 불순도 감소량이 임곗값 이하이다.

보통 위 조건들을 and 또는 or로 결합하여 사용합니다.



**예측 알고리즘**



예측 알고리즘은 매우 빠르게 동작합니다. 각 노드마다 간단한 질문 연산을 처리하면 되고, 트리의 깊이를 D라고 하면 O(D)만큼 걸리기 때문입니다.



결정트리는 독특한 특성이 있습니다.

1) 계량데이터에 더하여 비계량 데이터도 다룰 수 있습니다. (등식 질문을 만듭니다.)

2) 분류 결과를 해석할 수 있습니다. 경로에 있는 질문을 보면 왜 이런 분류 결과가 나왔는지 해석할 수 있습니다. (예. 쇼핑몰 고객 분류 결과)

3) 불안정한 분류기 입니다. 훈련 집합 또는 멈춤 조건의 임곗값이 조금만 바뀌어도 트리 모양이 크게 달라집니다. 앙상블은 이런 특성을 유용하게 사용합니다. 배깅은 불안정한 분류기를 결합해야 우수한 성능을 얻을 수 있기 때문입니다. 



### 2) Random Forest

결정트리는 신경망이나 SVM 등과 같은 다른 모델에 비해 정확도가 낮다는 약점이 있습니다.

따라서 결정 트리를 단독으로 쓰기보다는 앙상블의 요소 분류기로 주로 활용합니다.

결정트리는 배깅과 부스팅의 요소분류기로 활용할 수 있습니다.



결정 트리를 배깅으로 결합한 것을 **랜덤 포리스트**라고 합니다. 랜덤 포리스트는 가장 널리 활용되는 결정트리의 앙상블 모델입니다.

![](https://i.ibb.co/xFtqnhx/image.png)

line 8 에서 요소분류기로 결정트리가 지정된 것을 제외하면 Bagging과 완전히 같은 알고리즘입니다.

line 7 에서 훈련집합을 임의 샘플링 하므로 앙상블을 구성하는 결정 트리는 독립성을 가집니다. 여기에 독립성을 더 강화하기 위해 결정 트리 알고리즘을 약간 수정합니다.

 원래는 가능한 모든 후보 질문 중 최적의 질문을 찾아내 최적의 결정 트리를 제작하는 반면, 수정 후에는 특징을 임의로 뽑아 사용함으로써 결정 트리의 성능을 희생하는 대신, 앙상블의 독립성을 강화합니다.

즉, 훈련집합의 임의성과 특징의 임의성이 결합하여 앙상블의 독립성이 강화됩니다.

멈춤조건으로 분류기개수 T를 미리설정할 수도있고, 앙상블 성능이 임계값에 도달할 때로 설정할 수 도 있습니다.



**결정트리 수정**

> T에서 후보 질문을 생성한다.
>
> 모든 후보 질문의 불순도 감소량을 측정한다
>
> 불순도 감소량이 최대인 후보 질문 $\hat{q}$를 선택한다.

를 아래와 같이 수정합니다.

> 특징 벡터에서 임의로 특징($x_j$) 하나를 뽑는다.
>
> $x_j$의 최적 임곗값을 찾아 질문 $\hat{q}$를 만든다.



**Random Forest 장점**

1) 결정트리 특성을 이어받습니다.

2) 훈련집합 크기가 작아도 학습이 잘됩니다.

3) 특징 벡터의 차원이 큰 데이터에서도 높은 성능을 보입니다.



결정트리 학습 알고리즘은 greedy algorithm입니다. 즉, 전역에서가 아닌 지역 최적점을 찾는 한계를 가지고 있습니다. 이를 극복하는 과정에서 딥러닝과 결합하게 되었고, 딥러닝의 성능을 개선하는데 랜덤포리스트가 효과적으로 활용되고 있습니다.





## 4. 앙상블 결합

### 1) 부류 레이블(Class label)

가장 단순한 결합 방법은 투표(voting)입니다. 



**최다 득표(majority voting)**
$$
\hat{l} = \underset{i}{argmax} \sum_{k=1}^T o_i^{(k)}
$$


또는 과반 득표 방식이 있어, 과반이 없을 때는 기각(reject) 할 수도 있습니다.

더 보수적인 방법으로는 만장일치가 있고, 좀 더 정확률이 높아지는 대신, 기각률도 높아집니다.



---

AdaBoost로 생성된 요소 분류기는 신뢰도를 가지므로, 가중치 투표(weighted voting)가 가능합니다.



**가중치 투표**
$$
\hat{l} = \underset{i}{argmax} \sum_{k=1}^T \alpha_ko_i^{(k)}
$$


### 2) 부류 순위(Class ranking)

유권자가 c명의 후보에게 선호도 기준으로 순서를 표기하는 방식입니다.

주로 보르다 계수(Borda count)를 사용합니다.



우선 순위벡터를 점수벡터로 바꿔야합니다.

​	방법은 r순위에 c-r점을 부여하거나, r순위에 1/r점을 부여하는 것이 있습니다.

그 다음 점수벡터를 모두 더하고 가장 높은 점수를 얻은 부류를 선택합니다.



**보르다 계수(Borda count)**
$$
\hat{l} = \underset{i}{argmax} \sum_{k=1}^T s_i^{(k)}
$$


### 3) 부류 확률(Class probability)

가장 일반적인 형태의 정보로, 부류 레이블이나 부류 순위로 바꿀 수 있습니다.

하지만, 더 많은 정보를 내포하고 있으므로 그대로 활용하는 것이 좋습니다.





합(또는 평균)
$$
\beta_i = \sum_{k=1}^{T}\ o_i^{(k)} 또는\ \beta_i = \frac{1}{T}\sum_{k=1}^{T}\ o_i^{(k)} 
$$


가중 합
$$
\beta_i = \sum_{k=1}^{T}\ \alpha_io_i^{(k)} 
$$


최대
$$
\beta_i = \underset{k}{max}\ o_i^{(k)}
$$


최소
$$
\beta_i = \underset{k}{min}\ o_i^{(k)}
$$


메디안
$$
\beta_i = \underset{k}{median}\ o_i^{(k)}
$$


곱
$$
\beta_i = \prod_{k=1}^{T}\ o_i^{(k)}
$$


6가지 결합 규칙 중 하나를 사용하여, $\beta = (\beta_1, \beta_2, \cdots, \beta_c)^T$ 를 구한 후 다음식에서 부류를 선택하면 됩니다.
$$
\hat{l} = \underset{i}{argmax} \beta_i
$$
곱 규칙은 아주 낮은 확률을 출력할 시 최종 확률이 0에 가까워지는 문제가 있으므로 잘 사용하지 않고, 보통 평균을 많이 사용하고, 신뢰도가 주어지면 가중합을 주로 사용합니다.



 

## 5. 딥러닝과 앙상블

### 1. 평균 기법을 이용한 앙상블

AlexNet에서는 테스트 샘플 영상에서 5장을 잘라낸 후 각각을 반전하여 총 10장을 만듭니다. 영상 10장을 AlexNet에 입력하여 얻은 출력벡터 10개를 평균한 후 가장 큰 값을 가진 부류로 분류합니다.

**데이터 확대를 통해 1차 앙상블을 적용한 셈입니다.**



또한, 서로 다른 하이퍼 파라미터를 가진 AlexNet을 7개 학습한 후 출력 벡터 7개를 평균으로 결합한 결과를 이용해 더 낮은 오류율을 달성했습니다. 

**다중 분류기를 평균하는 2차 앙상블이라고 할 수 있습니다.**



GoogLeNet의 경우 영상 잘라내기는 144개까지 하였고, 신경망 개수도 7개까지 사용한 결과 오류율을 3.4% 감소시킬 수 있었습니다.

여기서 시간은 144 * 7 = 1,008배의 시간이 걸렸다고 합니다.



ResNet의 경우는 신경망 6개를 사용하여 0.92% 만큼의 오류율을 줄일 수 있었습니다.





### 2. 암시적 앙상블

**드랍아웃**

학습단계:

​	서로 다른 구조의 부분 신경망을 다수 생성합니다.

테스트단계:

​	여러 신경망의 출력을 평균하는 방식을 모방합니다. 하지만 여러 부분 신경망을 명시적으로 표현하는 대신, 가중치를 공유함으로써 암시적 앙상블 효과를 거둡니다.



**ResNet**

ResNet에서 conv 2개 층을 모듈, 지름길(residual path) 연결까지 포함한 것을 빌딩블록이라고 합니다. 3개의 모듈이 있고, 모듈이 수행하는 연산을 $f_1$ ~ $f_3$ 이라 표기하면 다음과 같이 수식을 유도할 수 있습니다.

![](https://pbs.twimg.com/media/CjG6ON5WkAEbrdv.jpg)
$$
\begin{align}
y_3 
& = y_2 + f_3(y_2) \\
& = (y_1 + f_2(y_1)) + f_3(y_1 + f_2(y_1)) \\
& = (y_0 + f_1(y_0) + f_2(y_0 + f_1(y_0)) + f_3(y_0 + f_1(y_0) + f_2(y_0 + f_1(y_0))
\end{align}
$$
풀어헤친 그림에 따르면 경로는 총 8개이고, (b)그림의 위에서부터 길이가 0, 1, 1, 2, 1, 2, 2, 3 입니다. 모듈이 3개여서 경로가 8개이므로, 일반적으로는 모듈이 k개이면 경로는 $2^k$개 입니다. 길이에 따른 경로의 개수는 이항분포를 따릅니다. (Veit, 2016)



ResNet 논문(He, 2016)은 신경망을 깊게 해서 성능향상을 얻었다고 결론내린 반면, **(Veit, 2016)**은 **ResNet이 앙상블처럼 동작한다**는 사실을 밝혔습니다.

VGG의 경우 모듈을 하나만 제거하여도 오류율이 90% 이상 되는데, ResNet은 모듈 하나를 제거하여도 성능 저하가 거의 없었습니다. 또한 모듈을 점차 1개씩 제거한 결과 ResNet 성능이 서서히 저하되는 현상이 관찰되었습니다.

오류 역전파 과정에서는 그레디언트 정보가 흐르는 결과를 관찰한 결과, 긴 경로에서는 흐르는 그레디언트가 0에 가깝고, 대부분은 짧은 경로로 흐른다는 사실을 밝혔습니다.

이러한 관찰을 바탕으로 ResNet의 높은 성능을 다수 경로의 앙상블 효과 때문으로 추정하였습니다.



**Stochastic depth** 기법은 ResNet학습시 임의로 선택된 빌딩 블록에서 모듈을 제거하고 지름길 연결만 남겨둔채 가중치 갱신을 수행합니다.(Huang, 2016)

드랍아웃과 유사한데, 드랍아웃은 임의로 선택한 가중치를 배제하는 반면, stochastic detph는 임의로 선택한 층을 배제합니다. 예측단계에서는 모든 층을 사용하는데 , 층별로 학습에 참여한 비율을 곱하여 가중치 합을 이용한 앙상블 효과를 거둡니다.

이처럼 stochastic detph를 적용했을 경우 1000층을 넘어도 꾸준히 성능 향상이 되었다고 합니다. 그 이유는 서로 다른 모듈을 제거한 아주 많은 앙상블 결합 효과 때문으로 해석합니다.



### 3. 깊은 랜덤 포레스트

랜덤 포리스트는 작은 규모 훈련집합을 가지고도 학습이 잘되며, 예측 결과를 해석할 수 있는 장점이 있지만, 표현 학습이 불가능하고, 노드에서 의사 결정이 결정론적이라는 단점이 있습니다.

하지만 랜덤포리스트의 장점은 딥러닝의 단점이고, 단점은 신경망의 장점이 됩니다.

이 때문에 랜덤포리스트를 딥러닝과 결합하여 우월한 성능을 확보한 연구가 진행되고 있습니다.



결정 트리는 노드에 있는 질문이 $x_i < \epsilon$에 따라 left, right로 갈리는 결정론적 의사결정인데, 이 질문을 매끄러운 시그모이드함수로 대치한 방법이 있습니다.

원래 학습 알고리즘으로 학습을 마친 후, 전역 최적화를 다시 시도하는데 이 때 leaf node에서 출발하여 root node로 진행하면서 오류 역전파와 유사한 알고리즘을 적용하여 노드의 질문을 조정합니다. (Suarez, 1999)



결정 트리를 등가의 신경망으로 변환하는 연구도 있습니다.(Sethil, 1990)

신경의 입력층에는 특징의 개수만큼 노드가 있고, 출력층에는 부류 개수만큼 노드가 있습니다.

첫번째 은닉층에서는 트리 내부노드에 해당하는 노드를 두고, 두번째 은닉층에는 leaf node에 해당하는 노드를 둡니다. 첫 번째 은닉층의 노드는 자신의 자손 leaf 노드와 에지로 연결됩니다.

두 번째 은닉층이 AND 연산, 출력층이 OR 연산을 수행하면 신경망과 결정 트리는 등가의 동작을 하게 됩니다.



랜덤 포리스트를 CNN으로 변환하여 CNN을 초기화 합니다. CNN을 학습한 후 랜덤포리스트로 역변환 하여 분할 문제에서 성능 향상이 나타났습니다. 이 방법은 훈련집합이 작아도 학습이 잘되는 랜덤포리스트와 표현학습을 수행할 수 있는 CNN의 장점을 결합한 접근방법입니다. (Richmond, 2015)



또한 랜덤 포리스트와 CNN을 여러 단계에 걸쳐 순차적으로 학습하였다면, 둘을 겹합하여 한꺼번에 학습하는 방법을 제시한 논문이 ICCV, 2015에서 Marr상이라 불리는 최우수 논문상을 수상하였습니다. (Kontschieder, 2015)