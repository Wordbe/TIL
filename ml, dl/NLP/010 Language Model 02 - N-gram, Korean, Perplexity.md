# Language Model 02 - N-gram, Korean, Perplexity

# 3 N-gram 언어 모델

n-gram 언어 모델도 카운트 기반한 통계적 접근을 사용하므로 SLM의 일종입니다. 다만, 이제는 이전에 나온 모든 단어를 고려하는 것이 아닌, 일부 단어(n개) 까지만 고려하는 접근 방법을 사용합니다.

<br>

### 1) 코퍼스에서 카운트하지 못하는 경우의 감소

SLM의 한계는 training corpus에 확률을 계산하고 싶은 문장이나 단어가 없을 수 있다는 점입니다. 또한 확률을 계산하고 싶은 문장이 길어질수록 갖고있는 코퍼스에서 그 문장이 존재하지 않을 가능성이 높아집니다. 그런데 그 참고하는 단어들의 개수를 줄이면 카운트 할 수 있을 가능성을 높일 수 있습니다.
$$
P(\text{is} \vert \text{An adorable little boy}) \approx P(\text{is} \vert \text{boy})
$$
위와 같이 더 짧은 시퀀스가 나올 확률과 근사하다고 가정을 할 수 도 있고, 조금 더 정책을 완하하여
$$
P(\text{is} \vert \text{An adorable little boy}) \approx P(\text{is} \vert \text{little boy})
$$
라고 가정할 수 도 있습니다. 이렇게 하면 해당 단어의 시퀀스를 카운트할 확률이 높아집니다.

<br>

### 2) N-gram

임의의 개수를 정하기 위한 기준을 위해 사용하는 것이 n-gram입니다.

> n-gram : n개의 연속적인 단어 나열

갖고 있는 코퍼스에서 n개의 뭉치 단위로 끊어서 이를 하나의 토큰으로 간주합니다. 

> **uni**grams : an, adorable, little, boy, is, spreading, smiles
> **bi**grams : an adorable, adorable little, little boy, boy is, is spreading, spreading smiles
> **tri**grams : an adorable little, adorable little boy, little boy is, boy is spreading, is spreading smiles
> **4**-grams : an adorable little boy, adorable little boy is, little boy is spreading, boy is spreading smiles

예를 들어 trigrams은 아래와 같은 원리로 계산됩니다.

![](https://wikidocs.net/images/page/21692/n-gram.PNG)

<br>

### 3) N-gram 언어 모델의 한계

n-gram은 뒤의 단어 몇 개만 보다보니 의도하고 싶은 대로 문장을 끝맺음하지 못하는 경우가 생깁니다. 결론적으로 전체 문장을 고려한 언어 모델보다 정확도가 떨어질 수밖에 없습니다.

#### (1) 희소문제(Sparsity Problem)

​	현실적으로 코퍼스에서 카운트할 수 있는 확률은 높일 수 있었지만, n-gram 언어 모델도 여전히 n-gram에 대한 희소 문제가 존재합니다.

#### (2) n을 선택할 때 trade-off 문제

n을 크게하면 문장이 올바른 지에 대한 정확도가 높아지므로, 언어 모델의 성능을 높일 수 있습니다. 하지만, 훈련 코퍼스에서 해당 n-gram을 카운트할 수 있는 확률이 적어지므로 희소 문제가 커집니다. 또한 모델 사이즈도 커지는 문제가 있습니다. 코퍼스의 모든 n-gram에 대해 카운트를 해야 하기 때문입니다.

trade-off 문제로 인해 정확도를 높이기 위해 $n \leq 5$ 로 정할 것을 권장합니다.

스탠퍼드 대학교 자료에 의하면, 월스트리트 저널에서 3,800만 개의 단어 토큰에 대해 n-gram 언어 모델을 학습하고, 1,500만 개의 테스트 데이터 셋에 데해 테스트 해보았을 때 아래와 같은 성능이 나왔습니다. Perplexity는 낮을수록 좋은 성능을 의미합니다.

| -              | **Unigram** | **Bigram** | **Trigram** |
| :------------- | :---------- | :--------- | :---------- |
| **Perplexity** | 962         | 170        | 109         |

<br>

# 4 한국어 언어 모델

한국어는 영어보다 토큰화도 까다로울 뿐만 아니라, 언어 모델로 다음 단어를 예측하기가 훨씬 어렵습니다. 그 이유를 알아봅니다.

### 1) 한국어는 어순이 중요하지 않다.

예를 들어보겠습니다.

Ex)
① 나는 운동을 합니다 체육관에서.
② 나는 체육관에서 운동을 합니다.
③ 체육관에서 운동을 합니다.
④ 나는 운동을 체육관에서 합니다.

4개의 문장은 전부 의미가 통하는 것을 알 수 있습니다. 심지어 '나는' 주어를 생략해도 말이 됩니다. 따라서 확률에 기반한 언어 모델이 다음 단어를 제대로 예측하기가 어렵습니다.

<br>

### 2) 한국어는 교착어다.

띄어쓰기 단위인 어절 단위로 토큰화를 할 경우 문장에서 발생가능한 단어의 수가 늘어납니다. 대표적 예로 교착어인 한국어에는 조사가 있습니다. 

가령 '그녀'라는 단어 하나만 해도 그녀가, 그녀를, 그녀의, 그녀와, 그녀로, 그녀께서, 그녀처럼 등과 같이 다양한 경우가 존재합니다. 그렇기 때문에, 한국어에서는 **토큰화**를 통해 접사나 조사 등을 분리하는 것은 중요한 작업이 되기도 합니다.

<br>

### 3) 한국어는 띄어쓰기가 제대로 지켜지지 않는다.

한국어는 띄어쓰기를 제대로 하지 않아도 의미가 전달되며, 띄어쓰기 규칙 또한 상대적으로 까다로운 언어이기 때문에 자연어 처리를 하는 것에 있어서 한국어 코퍼스는 띄어쓰기가 제대로 지켜지지 않는 경우가 많습니다. 토큰이 제대로 분리 되지 않는채 훈련 데이터로 사용된다면 언어 모델은 제대로 동작하지 않습니다.

<br>

# 5 Perplexity

 두 모델의 성능을 비교하고자, 일일히 모델들에 대해서 실제 작업을 시켜보고 정확도를 비교하는 작업은 공수가 너무 많이 드는 작업입니다. 이러한 평가를 외부 평가(extrinsic evaluation)라고 합니다.

이러한 평가보다 부정확하긴 하지만, 빠르게 식으로 계산되는 더 간단한 평가 방법이 있습니다. 바로 모델 내에서 자신의 성능을 수치화하여 결과를 내놓는 내부 평가(Intrinsic evaluation)에 해당되는 펄플렉서티(perplexity)입니다. 보통 줄여서 PPL 이라고 합니다.

### 1) 언어 모델의 평가 방법(Evaluation metric) : PPL

 perplexity는 복잡성, 헷갈리는 정도를 의미합니다. 즉 PPL은 '낮을수록' 언어 모델의 성능이 좋다는 것을 의미합니다. PPL은 단어의 수로 정규화된 테스트셋에 대한 확률의 역수입니다. PPL을 최소화한다는 것은 문장의 확률을 최대화 하는 것과 같습니다. 문장 $W$의 길이가 $N$이라고 할 때, PPL을 아래와 같습니다.
$$
PPL(W) = P(w_1, w_2, \dots, w_N)^{-\frac{1}{N}} = \sqrt[N]{\frac{1}{\prod_{i=1}^N P(w_i \vert w_1, w_2, \dots, w_{i-1})}}
$$
문장 확률 $P$ 에 n-gram을 적용할 수도 있습니다.

<br>

### 2) 분기 계수(Branching Factor)

PPL은 **선택할 수 있는 가능한 경우의 수를 의미하는 분기 계수**입니다. PPL은 이 언어 모델의 특정 시점에서 평균적으로 몇 개의 선택지를 가지고 고민하는지를 의미합니다. 

가령, 언어 모델에 어떤 테스트 데이터을 주고 측정했더니 PPL이 10이 나왔다고 해봅시다. 그렇다면 해당 언어 모델은 테스트 데이터에 대해서 다음 단어를 예측하는 모든 시점(time-step)마다 평균적으로 10개의 단어를 가지고 어떤 것이 정답인지 고민하고 있다고 볼 수 있습니다.
$$
PPL(W)=P(w_{1}, w_{2}, w_{3}, ... , w_{N})^{-\frac{1}{N}}=(\frac{1}{10}^{N})^{-\frac{1}{N}}=\frac{1}{10}^{-1}=10
$$
단, 평가 방법에 있어서 주의할 점은 PPL의 값이 낮다는 것은 테스트 데이터 상에서 높은 정확도를 보인다는 것이지, 사람이 직접 느끼기에 좋은 언어 모델이라는 것을 반드시 의미하진 않는다는 점입니다.





---

**Reference**

https://wikidocs.net/21692

https://wikidocs.net/22533

https://wikidocs.net/21697