# 작업 지원 도구

하둡에는 작업 지원, 모티러링을 위한 기능을 제공합니다.



## 1 DistCp

하둡은 클러스터 내 **대규모 데이터 이동을 위한 DistCp(Distribute Copy)** 기능을 제공합니다. 기본 파일 복사 명령은 파일을 하나씩 복사하지만, DistCp 기능을 이용하면, 맵리듀스를 이용하여 대규모의 파일을 병렬로 복사합니다.

**디스트카피는 맵리듀스 작업**입니다. **클러스터의 리소스를 이용하여 처리하기 때문에 커패시티 스케줄러를 이용하면 큐이름을 설정**해야 합니다.



### 사용법

```console
# a 폴더를 b 로 복사 
$ hadoop distcp hdfs:///user/a hdfs:///user/b

# a, b 폴더를 c로 복사 
$ hadoop distcp hdfs:///user/a hdfs:///user/b hdfs:///user/c

# -D 옵션을 이용하여 큐이름 설정 
$ hadoop distcp -Dmapred.job.queue.name=queue hdfs:///user/a hdfs:///user/b

# 파일이름, 사이즈를 비교하여 변경 내역있는 파일만 이동 
$ hadoop distcp -update hdfs:///user/a hdfs:///user/b hdfs:///user/c

# 목적지의 파일을 덮어씀 
$ hadoop distcp -overwrite hdfs:///user/a hdfs:///user/b hdfs:///user/c
```



---

## 2 하둡 아카이브(Hadoop Archive)

하둡 HDFS에서 작은 사이즈의 파일이 많아지면 네임노드(NameNode)는 이를 관리하는데 어려움을 겪게 됩니다.

 따라서 **블록사이즈 정도로 파일을 유지**해주는 것이 좋습니다. 이를 위해서 **하둡은 파일을 묶어서 관리**하고, 사용할 수 있는 하둡 아카이브(`Hadoop Archive`) 기능을 제공합니다.

**하둡 아카이브로 묶은 파일은 `har` 스키마를 이용해서 접근**합니다. 하둡 아카이브는 맵리듀스 작업을 이용해서 파일을 생성합니다. 생성된 아카이브는 `ls` 명령으로는 디렉토리처럼 보입니다. `har` 스키마를 이용해서 파일을 확인할 수 있습니다. 맵리듀스 작업의 입력으로 전달하면 하둡에서 데이터를 읽어서 처리합니다.

[Hadoop Archive](https://hadoop.apache.org/docs/current/hadoop-archives/HadoopArchives.html) 문서 바로가기



### 생성

하둡 아카이브 생성은 `archive` 커맨드를 이용합니다.

```
# 사용 방법 
hadoop archive -archiveName <NAME>.har -p <parent path> [-r <replication factor>]<src>* <dest>

# 사용 예제(큐 이름 적용)
$ hadoop archive -archiveName -Dmapred.job.queue.name=queue_name sample.har -p /user/data/ /user/
19/01/14 01:57:52 INFO mapreduce.Job: Job job_1520227878653_38308 running in uber mode : false
19/01/14 01:57:52 INFO mapreduce.Job:  map 0% reduce 0%
19/01/14 01:57:56 INFO mapreduce.Job:  map 100% reduce 0%
19/01/14 01:58:01 INFO mapreduce.Job:  map 100% reduce 100%
19/01/14 01:58:01 INFO mapreduce.Job: Job job_1520227878653_38308 completed successfully
19/01/14 01:58:01 INFO mapreduce.Job: Counters: 49
    File System Counters
        FILE: Number of bytes read=126

# sample.har 확인 
# ls 명령으로 보면 sample.har 디렉토리가 생성된 것을 알 수 있음 
$ hadoop fs -ls /user/
Found 1 items
drwxr-xr-x   - hadoop hadoop          0 2019-01-14 01:57 /user/sample.har

# sample.har 디렉토리 확인
$ hadoop fs -ls /user/sample.har/
Found 4 items
-rw-r--r--   2 hadoop hadoop          0 2019-01-14 01:57 /user/sample.har/_SUCCESS
-rw-r--r--   5 hadoop hadoop        117 2019-01-14 01:57 /user/sample.har/_index
-rw-r--r--   5 hadoop hadoop         23 2019-01-14 01:57 /user/sample.har/_masterindex
-rw-r--r--   2 hadoop hadoop        746 2019-01-14 01:57 /user/sample.har/part-0

# har 스키마를 이용한 데이터 확인 
$ hadoop fs -ls har:///user/sample.har/
Found 1 items
-rw-r--r--   2 hadoop hadoop        746 2018-05-23 04:15 har:///user/sample.har/test.txt
```

<br>

### 해제

하둡 아카이브 파일의 압축을 해제할 때는 `distcp`를 이용합니다.

```
#sample.har 압축 해제 
$ hadoop distcp -Dmapred.job.queue.name=queue_name har:///user/sample.har/ /user/decompress/

# 압축 해제 확인 
$ hadoop fs -ls /user/decompress/
Found 1 items
-rw-r--r--   2 hadoop hadoop        746 2019-01-14 04:04 /user/decompress/test.txt
```







---

**Reference**

https://wikidocs.net/25261

https://wikidocs.net/27605